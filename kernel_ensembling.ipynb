{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "ngrams = lambda a, n: list(zip(*[a[i:] for i in range(n)]))  # function that extract all the n grams in a given sequence\n",
    "\n",
    "\n",
    "def Combinations(proteins, n):\n",
    "    return list(product(proteins, repeat=n))\n",
    "\n",
    "\n",
    "def get_spectrum_embeddings(Seq, combinations, n):\n",
    "    kmers = ngrams(Seq, n)\n",
    "    embedding = np.zeros(len(combinations))\n",
    "    for ngram in kmers:\n",
    "        index = combinations.index(ngram)\n",
    "        embedding[index] += 1\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def get_mismatch_embeddings(Seq, combinations, n):\n",
    "    proteins = ['A', 'C', 'G', 'T']\n",
    "    decompose_seq = ngrams(Seq, n)\n",
    "    embedding = np.zeros(len(combinations))\n",
    "    for kmer in decompose_seq:\n",
    "        index = combinations.index(kmer)\n",
    "        embedding[index] += 1\n",
    "        kmer_seq = list(kmer)\n",
    "        for ind, cur_protein in enumerate(kmer_seq):\n",
    "            for protein in proteins:\n",
    "                if protein != cur_protein:\n",
    "                    mismatch_kmer = list(kmer_seq)\n",
    "                    mismatch_kmer[ind] = protein\n",
    "                    mismatch_kmer = tuple(mismatch_kmer)\n",
    "                    index_ = combinations.index(mismatch_kmer)\n",
    "                    embedding[index_] += 0.3\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def get_gram_matrix(X1, X2=[]):\n",
    "\n",
    "    n2 = len(X2)\n",
    "    n1 = len(X1)\n",
    "    if n2 == 0:\n",
    "        gram_matrix = X1 @ X1.T\n",
    "        gram_matrix_copy = X1 @ X1.T\n",
    "        gram_matrix = gram_matrix.astype(np.float32)\n",
    "        for i in range(n1):\n",
    "            for j in range(n1):\n",
    "                gram_matrix[i, j] /= (gram_matrix_copy[i, i] * gram_matrix_copy[j, j]) ** 0.5\n",
    "        print('Gram Matrix Computed for X1')\n",
    "        return gram_matrix\n",
    "    else:\n",
    "        gram_matrix = X1 @ X2.T\n",
    "        gram_matrix = gram_matrix.astype(np.float32)\n",
    "        gram_X1 = X1 @ X1.T\n",
    "        gram_X2 = X2 @ X2.T\n",
    "\n",
    "        for i in range(n1):\n",
    "            for j in range(n2):\n",
    "                gram_matrix[i, j] /= (gram_X2[j, j] * gram_X1[i, i]) ** 0.5\n",
    "        print('Gram Matrix Computed for X2')\n",
    "        return gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_gram_matrix(X1, X2=[]):\n",
    "\n",
    "    n2 = len(X2)\n",
    "    n1 = len(X1)\n",
    "    if n2 == 0:\n",
    "        gram_matrix = X1 @ X1.T\n",
    "        gram_matrix_copy = X1 @ X1.T\n",
    "        gram_matrix = gram_matrix.astype(np.float32)\n",
    "        for i in range(n1):\n",
    "            for j in range(n1):\n",
    "                gram_matrix[i, j] /= (gram_matrix_copy[i, i] * gram_matrix_copy[j, j]) ** 0.5\n",
    "        print('Gram Matrix Computed for X1')\n",
    "        return gram_matrix\n",
    "    else:\n",
    "        gram_matrix = X1 @ X2.T\n",
    "        gram_matrix = gram_matrix.astype(np.float32)\n",
    "        gram_X1 = X1 @ X1.T\n",
    "        gram_X2 = X2 @ X2.T\n",
    "\n",
    "        for i in range(n1):\n",
    "            for j in range(n2):\n",
    "                gram_matrix[i, j] /= (gram_X2[j, j] * gram_X1[i, i]) ** 0.5\n",
    "        print('Gram Matrix Computed for X2')\n",
    "        return gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "X_train_0 = (pd.read_csv('data/Xtr0.csv',header=None).values).tolist()\n",
    "Y_train_0 = (pd.read_csv('data/Ytr0.csv',sep=',',index_col=0).values)\n",
    "X_train_0 = (np.array(X_train_0)[1:,1]).tolist()\n",
    "X_test_0 = (pd.read_csv('data/Xte0.csv',header=None).values).tolist()\n",
    "X_test_0 = (np.array(X_test_0)[1:,1]).tolist()\n",
    "Y_train_0[Y_train_0 == 0] = -1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_0 = {'mismatch_6': [6, get_mismatch_embeddings],\n",
    "             'mismatch_7': [7, get_mismatch_embeddings],\n",
    "            'spectrum_7': [7, get_spectrum_embeddings],\n",
    "            'spectrum_6': [6, get_spectrum_embeddings]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gram_matrices/train_mismatch_6_dataset0.npy  already exists !\ngram_matrices/test_mismatch_6_dataset0.npy  already exists !\ngram_matrices/train_mismatch_7_dataset0.npy  already exists !\ngram_matrices/test_mismatch_7_dataset0.npy  already exists !\ngram_matrices/train_spectrum_7_dataset0.npy  already exists !\ngram_matrices/test_spectrum_7_dataset0.npy  already exists !\ngram_matrices/train_spectrum_6_dataset0.npy  already exists !\ngram_matrices/test_spectrum_6_dataset0.npy  already exists !\n"
     ]
    }
   ],
   "source": [
    "gram_matrices_0 = {}\n",
    "for key in kernels_0.keys():\n",
    "    train_filename = 'gram_matrices/train_' + key + '_dataset0.npy'\n",
    "    test_filename = 'gram_matrices/test_' + key + '_dataset0.npy'\n",
    "    length = kernels_0[key][0]\n",
    "    embedding_func = kernels_0[key][1]\n",
    "    DNA_combinations = Combinations(proteins=['A', 'C', 'G', 'T'], n=length)\n",
    "    \n",
    "    if os.path.exists(train_filename):\n",
    "        print(train_filename, ' already exists !')\n",
    "        gram_train_0 = np.load(train_filename)\n",
    "    else:\n",
    "        print('Creating ', train_filename)\n",
    "        train_embeddings_0 = np.empty([len(X_train_0), len(DNA_combinations)])\n",
    "        for i in tqdm(range(len(X_train_0))):\n",
    "            train_embeddings_0[i, :] = embedding_func(Seq=X_train_0[i], combinations=DNA_combinations, n=length)\n",
    "        gram_train_0 = get_gram_matrix(train_embeddings_0)\n",
    "        np.save(train_filename, gram_train_0)\n",
    "    if os.path.exists(test_filename):\n",
    "        print(test_filename, ' already exists !')\n",
    "        gram_test_0 = np.load(test_filename)\n",
    "    else:\n",
    "        print('Creating ', test_filename)\n",
    "        test_embeddings_0 = np.empty([len(X_test_0), len(DNA_combinations)])\n",
    "        for i in tqdm(range(len(X_test_0))):\n",
    "            test_embeddings_0[i, :] = embedding_func(Seq=X_test_0[i], combinations=DNA_combinations, n=length)\n",
    "        gram_test_0 = get_gram_matrix(train_embeddings_0, test_embeddings_0)\n",
    "        np.save(test_filename, gram_test_0)\n",
    "    gram_matrices_0[key] = {'train': gram_train_0,\n",
    "                           'test': gram_test_0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxopt\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "\n",
    "class SVMC:\n",
    "\n",
    "    def __init__(self, c=1, min_sv=1e-4):\n",
    "        self.alpha_ = None\n",
    "        self.c = c  # corresponds to (1/2*lambda)\n",
    "        # if y_train is not None: self.C = float(self.C)\n",
    "        self.min_sv = min_sv\n",
    "\n",
    "    def fit(self, kernel_train, label):\n",
    "        n = label.shape[0]\n",
    "        p = kernel_train.shape[1]\n",
    "        diag = np.zeros((n, n))\n",
    "        np.fill_diagonal(diag, label)\n",
    "\n",
    "        # P = kernel_train.copy()\n",
    "        # for i in range(n):\n",
    "        #     P[i, :] = P[i, :]*label[i]\n",
    "\n",
    "        P = np.dot(diag, np.dot(kernel_train, diag))\n",
    "        Pcvx = cvxopt.matrix(P)\n",
    "\n",
    "        Pcvx = cvxopt.matrix(np.outer(label,label) * kernel_train)\n",
    "        qcvx = cvxopt.matrix(np.ones(n) * -1)\n",
    "\n",
    "        if self.c is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n))\n",
    "        else:\n",
    "            Ginf = np.diag(np.ones(n) * -1)\n",
    "            Gsup = np.identity(n)\n",
    "            G = cvxopt.matrix(np.vstack((Ginf, Gsup)))\n",
    "            hinf = np.zeros(n)\n",
    "            hsup = np.ones(n) * self.c\n",
    "            h = cvxopt.matrix(np.hstack((hinf, hsup)))\n",
    "\n",
    "        A = label.transpose()\n",
    "        A = A.astype('double')\n",
    "        Acvx = cvxopt.matrix(A)\n",
    "        bcvx = cvxopt.matrix(0.0)\n",
    "\n",
    "        # Solve QP problem using cvxopt solver for qp problems\n",
    "        u = cvxopt.solvers.qp(Pcvx, qcvx, G, h, Acvx, bcvx)\n",
    "\n",
    "        # take Lagrange multipliers, and the solution of the dual problem\n",
    "        alpha = np.ravel(u['x'])\n",
    "\n",
    "        sv = alpha > self.min_sv\n",
    "        ind = np.arange(len(alpha))[sv]\n",
    "\n",
    "        self.alpha_ = alpha[sv]\n",
    "        self.sv = np.argwhere(sv == True)\n",
    "        self.sv_label = label[sv]\n",
    "        print(\"%d support vectors out of %d points\" % (len(self.alpha_), n))\n",
    "\n",
    "        # Bias value/intercept\n",
    "        self.b = 0 * 1.0\n",
    "        # self.b = self.b.astype(np.float64)\n",
    "        for i in range(len(self.alpha_)):\n",
    "            self.b += self.sv_label[i]\n",
    "            self.b -= np.sum(self.alpha_ * self.sv_label[:, 0] * kernel_train[sv, ind[i]])\n",
    "        self.b /= len(self.alpha_)\n",
    "\n",
    "    def get_coef(self):\n",
    "        return list(self.alpha_)\n",
    "\n",
    "    def predict(self, kernel_test):\n",
    "        \n",
    "        y_predict = np.zeros(kernel_test.shape[1])\n",
    "\n",
    "        for i in range(kernel_test.shape[1]):\n",
    "            y_predict[i] = sum(alpha * sv_label * kernel_test[sv, i] for alpha, sv, sv_label in\n",
    "                               zip(self.alpha_, self.sv, self.sv_label[:, 0]))\n",
    "        return y_predict + self.b\n",
    "\n",
    "        prediction = np.sign(y_predict + self.b)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def predict_class(self, kernel_test):\n",
    "        \n",
    "        prediction = np.array(self.predict(kernel_test) >= 0, dtype=int)\n",
    "        prediction[prediction == 0] = -1\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "class KernelPCA():\n",
    "    \n",
    "    def __init__(self, n_components):\n",
    "        \n",
    "        self.number_components = n_components\n",
    "    \n",
    "    # @staticmethod\n",
    "    def get_wanted_eigenvectors_eigenvalues(self, w, v, ):\n",
    "        \n",
    "        L = [(w[i], v[i, :]) for i in range(w.shape[0])]\n",
    "        L = sorted(L, key=lambda x: x[0], reverse=True)\n",
    "        return np.array([L[i][0] for i in range(self.number_components)]),\\\n",
    "               np.array([L[i][1] for i in range(self.number_components)])\n",
    "\n",
    "\n",
    "    def fit_transform(self, K, eps=1e-6):\n",
    "        \n",
    "        n = K.shape[0]\n",
    "        U = (1/n) * np.ones((n, n))\n",
    "        centred_K = (np.eye(n) - U)@K@(np.eye(n) - U)\n",
    "        \n",
    "        w, v = np.linalg.eig(centred_K)\n",
    "        w = np.array(list(map(lambda x: x.real if x.real > 0 else eps, w)))\n",
    "        v = np.real(v)\n",
    "        w, v = self.get_wanted_eigenvectors_eigenvalues(w, v)\n",
    "        \n",
    "        alpha = v/np.sqrt(w[:, None])\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        return K @ alpha.T\n",
    "    def transform(self, X):\n",
    "\n",
    "        return X@self.alpha.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicting with mismatch_6 and n_component=100\n",
      "1533 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6425\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1479 support vectors out of 1600 points\n",
      "Val Accuracy = 0.61\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1449 support vectors out of 1600 points\n",
      "Val Accuracy = 0.61\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1433 support vectors out of 1600 points\n",
      "Val Accuracy = 0.625\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1419 support vectors out of 1600 points\n",
      "Val Accuracy = 0.63\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1394 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6025\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1447 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6475\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1384 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6025\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1371 support vectors out of 1600 points\n",
      "Val Accuracy = 0.62\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1339 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6125\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1339 support vectors out of 1600 points\n",
      "Val Accuracy = 0.62\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1314 support vectors out of 1600 points\n",
      "Val Accuracy = 0.625\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1368 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6125\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1311 support vectors out of 1600 points\n",
      "Val Accuracy = 0.64\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1291 support vectors out of 1600 points\n",
      "Val Accuracy = 0.62\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1301 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6625\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1290 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6575\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1281 support vectors out of 1600 points\n",
      "Val Accuracy = 0.665\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1347 support vectors out of 1600 points\n",
      "Val Accuracy = 0.63\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1310 support vectors out of 1600 points\n",
      "Val Accuracy = 0.65\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1285 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6275\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1276 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6625\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1255 support vectors out of 1600 points\n",
      "Val Accuracy = 0.615\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1243 support vectors out of 1600 points\n",
      "Val Accuracy = 0.625\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1295 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6425\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1265 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6325\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1267 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6675\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1239 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6575\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1236 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6775\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1210 support vectors out of 1600 points\n",
      "Val Accuracy = 0.635\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1283 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6425\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1254 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6575\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1229 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6425\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1234 support vectors out of 1600 points\n",
      "Val Accuracy = 0.65\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1198 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6225\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1198 support vectors out of 1600 points\n",
      "Val Accuracy = 0.615\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1288 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6825\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1254 support vectors out of 1600 points\n",
      "Val Accuracy = 0.64\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1197 support vectors out of 1600 points\n",
      "Val Accuracy = 0.61\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1219 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6425\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1185 support vectors out of 1600 points\n",
      "Val Accuracy = 0.605\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1173 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6475\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "1248 support vectors out of 1600 points\n",
      "Val Accuracy = 0.65\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "1199 support vectors out of 1600 points\n",
      "Val Accuracy = 0.645\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "1185 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6475\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "1188 support vectors out of 1600 points\n",
      "Val Accuracy = 0.67\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "1171 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6625\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "1157 support vectors out of 1600 points\n",
      "Val Accuracy = 0.635\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "1237 support vectors out of 1600 points\n",
      "Val Accuracy = 0.665\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "1189 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6275\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "1160 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6375\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "1135 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6275\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "1132 support vectors out of 1600 points\n",
      "Val Accuracy = 0.62\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "1139 support vectors out of 1600 points\n",
      "Val Accuracy = 0.62\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "1211 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6375\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "1186 support vectors out of 1600 points\n",
      "Val Accuracy = 0.64\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "1148 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6325\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "1134 support vectors out of 1600 points\n",
      "Val Accuracy = 0.63\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "1147 support vectors out of 1600 points\n",
      "Val Accuracy = 0.685\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "1129 support vectors out of 1600 points\n",
      "Val Accuracy = 0.655\n",
      "--------------------------------------------------\n",
      "For the kernel mismatch_6 the best accuracy is 0.685 with n_components=1000 and c=2.5\n",
      "--------------------------------------------------\n",
      "1393 support vectors out of 2000 points\n"
     ]
    }
   ],
   "source": [
    "# With PCA\n",
    "list_c = [0.5, 1, 1.5, 2, 2.5, 3] \n",
    "sv = 1e-4\n",
    "lambda_log_reg = 1\n",
    "tolerance = 0.001\n",
    "list_kernels = list(gram_matrices_0.keys())\n",
    "list_of_prediction_test_0 = []\n",
    "NComponents = [100*i for i in range(1, 11)]\n",
    "from sklearn.metrics import accuracy_score\n",
    "for kernel in ['mismatch_6']:\n",
    "    ValAcc = np.zeros((len(NComponents), len(list_c)))\n",
    "    for i in range(len(NComponents)):\n",
    "        for j in range(len(list_c)):\n",
    "            \n",
    "            n_component = NComponents[i]\n",
    "            c = list_c[j]\n",
    "\n",
    "            print(f'Predicting with {kernel} and n_component={n_component}')\n",
    "            gram_train_0 = gram_matrices_0[kernel]['train']\n",
    "            \n",
    "            pca = KernelPCA(n_components=n_component)\n",
    "            gram_train_0 = pca.fit_transform(gram_train_0)\n",
    "            gram_train_0 = gram_train_0@gram_train_0.T\n",
    "\n",
    "            test_size = 0.2\n",
    "            list_train, list_val = train_test_split(list(range(2000)), test_size=test_size)\n",
    "            gram_train = gram_train_0[list_train, :][:, list_train]\n",
    "            gram_val = gram_train_0[list_train, :][:, list_val]\n",
    "            y_train_split_0 = Y_train_0[list_train]\n",
    "            y_val_split_0 = Y_train_0[list_val]\n",
    "\n",
    "            svm_test = SVMC(c=c, min_sv=sv)\n",
    "\n",
    "            svm_test.fit(gram_train, y_train_split_0)\n",
    "            y_val_pred = svm_test.predict_class(gram_val).reshape(-1)\n",
    "            val_acc = accuracy_score(y_val_split_0.reshape(-1), y_val_pred)\n",
    "            ValAcc[i, j] = val_acc\n",
    "            print('Val Accuracy =', val_acc)\n",
    "    \n",
    "    best_ncomponent_arg, best_c_arg = np.unravel_index(np.argmax(ValAcc, axis=None), ValAcc.shape) \n",
    "    best_ncomponent = NComponents[best_ncomponent_arg]\n",
    "    best_c = list_c[best_c_arg]\n",
    "    print('--------------------------------------------------')\n",
    "    print('For the kernel {} the best accuracy is {} with n_components={} and c={}'.format(kernel, np.max(ValAcc), best_ncomponent, best_c))\n",
    "    print('--------------------------------------------------')\n",
    "\n",
    "    svm_test = SVMC(c=best_c, min_sv=sv)\n",
    "    pca = KernelPCA(n_components=best_ncomponent)\n",
    "\n",
    "    gram_train_0 = gram_matrices_0[kernel]['train']\n",
    "    gram_train_0_pca = pca.fit_transform(gram_train_0)\n",
    "    gram_train_0 = gram_train_0_pca@gram_train_0_pca.T\n",
    "    svm_test.fit(gram_train_0, Y_train_0)\n",
    "    \n",
    "    gram_test_0 = gram_matrices_0[kernel]['test'].T\n",
    "    gram_test_0_pca = pca.transform(gram_test_0)\n",
    "    gram_test_0 = gram_train_0_pca@gram_test_0_pca.T\n",
    "\n",
    "    y_test_pred_0 = svm_test.predict_class(gram_test_0)\n",
    "    y_test_pred_0[y_test_pred_0 == -1] = 0\n",
    "    list_of_prediction_test_0.append(y_test_pred_0)\n",
    "\n",
    "y_pred_0 = np.array(np.array(list_of_prediction_test_0).mean(axis=0).reshape((-1,))>0.5,dtype=int)\n"
   ]
  },
  {
   "source": [
    "# Part 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_1 = (pd.read_csv('data/Xtr1.csv',header=None).values).tolist()\n",
    "Y_train_1 = (pd.read_csv('data/Ytr1.csv',sep=',',index_col=0).values)\n",
    "X_train_1 = (np.array(X_train_1)[1:,1]).tolist()\n",
    "X_test_1 = (pd.read_csv('data/Xte1.csv',header=None).values).tolist()\n",
    "X_test_1 = (np.array(X_test_1)[1:,1]).tolist()\n",
    "Y_train_1[Y_train_1 == 0] = -1\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gram_matrices/train_mismatch_6_dataset1.npy  already exists !\n",
      "gram_matrices/test_mismatch_6_dataset1.npy  already exists !\n",
      "gram_matrices/train_mismatch_7_dataset1.npy  already exists !\n",
      "gram_matrices/test_mismatch_7_dataset1.npy  already exists !\n",
      "gram_matrices/train_spectrum_7_dataset1.npy  already exists !\n",
      "gram_matrices/test_spectrum_7_dataset1.npy  already exists !\n",
      "gram_matrices/train_spectrum_6_dataset1.npy  already exists !\n",
      "gram_matrices/test_spectrum_6_dataset1.npy  already exists !\n"
     ]
    }
   ],
   "source": [
    "kernels_1 = {'mismatch_6': [6, get_mismatch_embeddings],\n",
    "             'mismatch_7': [7, get_mismatch_embeddings],\n",
    "            'spectrum_7': [7, get_spectrum_embeddings],\n",
    "            'spectrum_6': [6, get_spectrum_embeddings]}\n",
    "\n",
    "gram_matrices_1 = {}\n",
    "for key in kernels_1.keys():\n",
    "    train_filename = 'gram_matrices/train_' + key + '_dataset1.npy'\n",
    "    test_filename = 'gram_matrices/test_' + key + '_dataset1.npy'\n",
    "    length = kernels_1[key][0]\n",
    "    embedding_func = kernels_1[key][1]\n",
    "    DNA_combinations = Combinations(proteins=['A', 'C', 'G', 'T'], n=length)\n",
    "    \n",
    "    if os.path.exists(train_filename):\n",
    "        print(train_filename, ' already exists !')\n",
    "        gram_train_1 = np.load(train_filename)\n",
    "    else:\n",
    "        print('Creating ', train_filename)\n",
    "        train_embeddings_1 = np.empty([len(X_train_1), len(DNA_combinations)])\n",
    "        for i in tqdm(range(len(X_train_1))):\n",
    "            train_embeddings_1[i, :] = embedding_func(Seq=X_train_1[i], combinations=DNA_combinations, n=length)\n",
    "        gram_train_1 = get_gram_matrix(train_embeddings_1)\n",
    "        np.save(train_filename, gram_train_1)\n",
    "    if os.path.exists(test_filename):\n",
    "        print(test_filename, ' already exists !')\n",
    "        gram_test_1 = np.load(test_filename)\n",
    "    else:\n",
    "        print('Creating ', test_filename)\n",
    "        test_embeddings_1 = np.empty([len(X_test_1), len(DNA_combinations)])\n",
    "        for i in tqdm(range(len(X_test_1))):\n",
    "            test_embeddings_1[i, :] = embedding_func(Seq=X_test_1[i], combinations=DNA_combinations, n=length)\n",
    "        gram_test_1 = get_gram_matrix(train_embeddings_1, test_embeddings_1)\n",
    "        np.save(test_filename, gram_test_1)\n",
    "    gram_matrices_1[key] = {'train': gram_train_1,\n",
    "                           'test': gram_test_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicting with mismatch_6 and n_component=100\n",
      "1577 support vectors out of 1600 points\n",
      "Val Accuracy = 0.575\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1552 support vectors out of 1600 points\n",
      "Val Accuracy = 0.59\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1539 support vectors out of 1600 points\n",
      "Val Accuracy = 0.5525\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1535 support vectors out of 1600 points\n",
      "Val Accuracy = 0.57\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1515 support vectors out of 1600 points\n",
      "Val Accuracy = 0.5575\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1510 support vectors out of 1600 points\n",
      "Val Accuracy = 0.63\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1510 support vectors out of 1600 points\n",
      "Val Accuracy = 0.535\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1492 support vectors out of 1600 points\n",
      "Val Accuracy = 0.595\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1460 support vectors out of 1600 points\n",
      "Val Accuracy = 0.59\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1439 support vectors out of 1600 points\n",
      "Val Accuracy = 0.5925\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1432 support vectors out of 1600 points\n",
      "Val Accuracy = 0.63\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1424 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6225\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1497 support vectors out of 1600 points\n",
      "Val Accuracy = 0.5975\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1422 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6325\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1367 support vectors out of 1600 points\n",
      "Val Accuracy = 0.575\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1373 support vectors out of 1600 points\n",
      "Val Accuracy = 0.645\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1357 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6475\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1328 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6325\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1426 support vectors out of 1600 points\n",
      "Val Accuracy = 0.5875\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1374 support vectors out of 1600 points\n",
      "Val Accuracy = 0.61\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1324 support vectors out of 1600 points\n",
      "Val Accuracy = 0.63\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1314 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6325\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1301 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6525\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1297 support vectors out of 1600 points\n",
      "Val Accuracy = 0.665\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1395 support vectors out of 1600 points\n",
      "Val Accuracy = 0.625\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1346 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6475\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1304 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6475\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1281 support vectors out of 1600 points\n",
      "Val Accuracy = 0.675\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1268 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6625\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1237 support vectors out of 1600 points\n",
      "Val Accuracy = 0.625\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1377 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6475\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1301 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6425\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1271 support vectors out of 1600 points\n",
      "Val Accuracy = 0.65\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1244 support vectors out of 1600 points\n",
      "Val Accuracy = 0.635\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1242 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6675\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1227 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6525\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1336 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6625\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1271 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6075\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1235 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6375\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1220 support vectors out of 1600 points\n",
      "Val Accuracy = 0.63\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1192 support vectors out of 1600 points\n",
      "Val Accuracy = 0.62\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1199 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6325\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "1286 support vectors out of 1600 points\n",
      "Val Accuracy = 0.63\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "1223 support vectors out of 1600 points\n",
      "Val Accuracy = 0.645\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "1213 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6125\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "1172 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6325\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "1165 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6275\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "1141 support vectors out of 1600 points\n",
      "Val Accuracy = 0.605\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "1259 support vectors out of 1600 points\n",
      "Val Accuracy = 0.645\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "1202 support vectors out of 1600 points\n",
      "Val Accuracy = 0.645\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "1183 support vectors out of 1600 points\n",
      "Val Accuracy = 0.645\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "1140 support vectors out of 1600 points\n",
      "Val Accuracy = 0.595\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "1149 support vectors out of 1600 points\n",
      "Val Accuracy = 0.645\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "1128 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6375\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "1219 support vectors out of 1600 points\n",
      "Val Accuracy = 0.605\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "1179 support vectors out of 1600 points\n",
      "Val Accuracy = 0.615\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "1150 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6325\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "1145 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6275\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "1128 support vectors out of 1600 points\n",
      "Val Accuracy = 0.65\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "1085 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6275\n",
      "--------------------------------------------------\n",
      "For the kernel mismatch_6 the best accuracy is 0.675 with n_components=500 and c=2\n",
      "--------------------------------------------------\n",
      "1580 support vectors out of 2000 points\n"
     ]
    }
   ],
   "source": [
    "# With PCA\n",
    "list_c = [0.5, 1, 1.5, 2, 2.5, 3]  \n",
    "sv = 1e-4\n",
    "lambda_log_reg = 1\n",
    "tolerance = 0.001\n",
    "list_kernels = list(gram_matrices_1.keys())\n",
    "list_of_prediction_test_1 = []\n",
    "NComponents = [100*i for i in range(1, 11)]\n",
    "from sklearn.metrics import accuracy_score\n",
    "for kernel in ['mismatch_6']:\n",
    "    ValAcc = np.zeros((len(NComponents), len(list_c)))\n",
    "    for i in range(len(NComponents)):\n",
    "        for j in range(len(list_c)):\n",
    "            \n",
    "            n_component = NComponents[i]\n",
    "            c = list_c[j]\n",
    "\n",
    "            print(f'Predicting with {kernel} and n_component={n_component}')\n",
    "            gram_train_1 = gram_matrices_1[kernel]['train']\n",
    "            \n",
    "            pca = KernelPCA(n_components=n_component)\n",
    "            gram_train_1 = pca.fit_transform(gram_train_1)\n",
    "            gram_train_1 = gram_train_1@gram_train_1.T\n",
    "\n",
    "            test_size = 0.2\n",
    "            list_train, list_val = train_test_split(list(range(2000)), test_size=test_size)\n",
    "            gram_train = gram_train_1[list_train, :][:, list_train]\n",
    "            gram_val = gram_train_1[list_train, :][:, list_val]\n",
    "            y_train_split_1 = Y_train_1[list_train]\n",
    "            y_val_split_1 = Y_train_1[list_val]\n",
    "\n",
    "            svm_test = SVMC(c=c, min_sv=sv)\n",
    "\n",
    "            svm_test.fit(gram_train, y_train_split_1)\n",
    "            y_val_pred = svm_test.predict_class(gram_val).reshape(-1)\n",
    "            val_acc = accuracy_score(y_val_split_1.reshape(-1), y_val_pred)\n",
    "            ValAcc[i, j] = val_acc\n",
    "            print('Val Accuracy =', val_acc)\n",
    "    \n",
    "    best_ncomponent_arg, best_c_arg = np.unravel_index(np.argmax(ValAcc, axis=None), ValAcc.shape) \n",
    "    best_ncomponent = NComponents[best_ncomponent_arg]\n",
    "    best_c = list_c[best_c_arg]\n",
    "    print('--------------------------------------------------')\n",
    "    print('For the kernel {} the best accuracy is {} with n_components={} and c={}'.format(kernel, np.max(ValAcc), best_ncomponent, best_c))\n",
    "    print('--------------------------------------------------')\n",
    "\n",
    "    svm_test = SVMC(c=best_c, min_sv=sv)\n",
    "    pca = KernelPCA(n_components=best_ncomponent)\n",
    "\n",
    "    gram_train_1 = gram_matrices_1[kernel]['train']\n",
    "    gram_train_1_pca = pca.fit_transform(gram_train_1)\n",
    "    gram_train_1 = gram_train_1_pca@gram_train_1_pca.T\n",
    "    svm_test.fit(gram_train_1, Y_train_1)\n",
    "    \n",
    "    gram_test_1 = gram_matrices_1[kernel]['test'].T\n",
    "    gram_test_1_pca = pca.transform(gram_test_1)\n",
    "    gram_test_1 = gram_train_1_pca@gram_test_1_pca.T\n",
    "\n",
    "    y_test_pred_1 = svm_test.predict_class(gram_test_1)\n",
    "    y_test_pred_1[y_test_pred_1 == -1] = 0\n",
    "    list_of_prediction_test_1.append(y_test_pred_1)\n",
    "\n",
    "y_pred_1 = np.array(np.array(list_of_prediction_test_1).mean(axis=0).reshape((-1,))>0.5,dtype=int)\n"
   ]
  },
  {
   "source": [
    "# PART 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_2 = (pd.read_csv('data/Xtr2.csv',header=None).values).tolist()\n",
    "Y_train_2 = (pd.read_csv('data/Ytr2.csv',sep=',',index_col=0).values)\n",
    "X_train_2 = (np.array(X_train_2)[1:,1]).tolist()\n",
    "X_test_2 = (pd.read_csv('data/Xte2.csv',header=None).values).tolist()\n",
    "X_test_2 = (np.array(X_test_2)[1:,1]).tolist()\n",
    "Y_train_2[Y_train_2 == 0] = -1\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gram_matrices/train_mismatch_6_dataset2.npy  already exists !\ngram_matrices/test_mismatch_6_dataset2.npy  already exists !\ngram_matrices/train_mismatch_7_dataset2.npy  already exists !\ngram_matrices/test_mismatch_7_dataset2.npy  already exists !\ngram_matrices/train_spectrum_7_dataset2.npy  already exists !\ngram_matrices/test_spectrum_7_dataset2.npy  already exists !\ngram_matrices/train_spectrum_6_dataset2.npy  already exists !\ngram_matrices/test_spectrum_6_dataset2.npy  already exists !\n"
     ]
    }
   ],
   "source": [
    "kernels_2 = {'mismatch_6': [6, get_mismatch_embeddings],\n",
    "             'mismatch_7': [7, get_mismatch_embeddings],\n",
    "            'spectrum_7': [7, get_spectrum_embeddings],\n",
    "            'spectrum_6': [6, get_spectrum_embeddings]}\n",
    "\n",
    "gram_matrices_2 = {}\n",
    "for key in kernels_2.keys():\n",
    "    train_filename = 'gram_matrices/train_' + key + '_dataset2.npy'\n",
    "    test_filename = 'gram_matrices/test_' + key + '_dataset2.npy'\n",
    "    length = kernels_2[key][0]\n",
    "    embedding_func = kernels_2[key][1]\n",
    "    DNA_combinations = Combinations(proteins=['A', 'C', 'G', 'T'], n=length)\n",
    "    \n",
    "    if os.path.exists(train_filename):\n",
    "        print(train_filename, ' already exists !')\n",
    "        gram_train_2 = np.load(train_filename)\n",
    "    else:\n",
    "        print('Creating ', train_filename)\n",
    "        train_embeddings_2 = np.empty([len(X_train_2), len(DNA_combinations)])\n",
    "        for i in tqdm(range(len(X_train_2))):\n",
    "            train_embeddings_2[i, :] = embedding_func(Seq=X_train_2[i], combinations=DNA_combinations, n=length)\n",
    "        gram_train_2 = get_gram_matrix(train_embeddings_2)\n",
    "        np.save(train_filename, gram_train_2)\n",
    "    if os.path.exists(test_filename):\n",
    "        print(test_filename, ' already exists !')\n",
    "        gram_test_2 = np.load(test_filename)\n",
    "    else:\n",
    "        print('Creating ', test_filename)\n",
    "        test_embeddings_2 = np.empty([len(X_test_2), len(DNA_combinations)])\n",
    "        for i in tqdm(range(len(X_test_2))):\n",
    "            test_embeddings_2[i, :] = embedding_func(Seq=X_test_2[i], combinations=DNA_combinations, n=length)\n",
    "        gram_test_2 = get_gram_matrix(train_embeddings_2, test_embeddings_2)\n",
    "        np.save(test_filename, gram_test_2)\n",
    "    gram_matrices_2[key] = {'train': gram_train_2,\n",
    "                           'test': gram_test_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicting with mismatch_6 and n_component=100\n",
      "1400 support vectors out of 1600 points\n",
      "Val Accuracy = 0.655\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1320 support vectors out of 1600 points\n",
      "Val Accuracy = 0.705\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1286 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6825\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1261 support vectors out of 1600 points\n",
      "Val Accuracy = 0.72\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1260 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6975\n",
      "Predicting with mismatch_6 and n_component=100\n",
      "1216 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6375\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1255 support vectors out of 1600 points\n",
      "Val Accuracy = 0.665\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1214 support vectors out of 1600 points\n",
      "Val Accuracy = 0.6775\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1184 support vectors out of 1600 points\n",
      "Val Accuracy = 0.715\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1167 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7125\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1148 support vectors out of 1600 points\n",
      "Val Accuracy = 0.69\n",
      "Predicting with mismatch_6 and n_component=200\n",
      "1114 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1171 support vectors out of 1600 points\n",
      "Val Accuracy = 0.71\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1123 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7375\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1098 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7675\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1069 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7075\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1063 support vectors out of 1600 points\n",
      "Val Accuracy = 0.735\n",
      "Predicting with mismatch_6 and n_component=300\n",
      "1025 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7075\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1123 support vectors out of 1600 points\n",
      "Val Accuracy = 0.715\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1073 support vectors out of 1600 points\n",
      "Val Accuracy = 0.705\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1060 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7175\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1056 support vectors out of 1600 points\n",
      "Val Accuracy = 0.74\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1039 support vectors out of 1600 points\n",
      "Val Accuracy = 0.76\n",
      "Predicting with mismatch_6 and n_component=400\n",
      "1024 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7325\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1108 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7175\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1046 support vectors out of 1600 points\n",
      "Val Accuracy = 0.725\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1021 support vectors out of 1600 points\n",
      "Val Accuracy = 0.69\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1017 support vectors out of 1600 points\n",
      "Val Accuracy = 0.75\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "1018 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7225\n",
      "Predicting with mismatch_6 and n_component=500\n",
      "989 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7125\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1075 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7425\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1036 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7225\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "976 support vectors out of 1600 points\n",
      "Val Accuracy = 0.71\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "1011 support vectors out of 1600 points\n",
      "Val Accuracy = 0.74\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "975 support vectors out of 1600 points\n",
      "Val Accuracy = 0.715\n",
      "Predicting with mismatch_6 and n_component=600\n",
      "996 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7475\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1040 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7275\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "1001 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7175\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "979 support vectors out of 1600 points\n",
      "Val Accuracy = 0.73\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "978 support vectors out of 1600 points\n",
      "Val Accuracy = 0.715\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "953 support vectors out of 1600 points\n",
      "Val Accuracy = 0.73\n",
      "Predicting with mismatch_6 and n_component=700\n",
      "984 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7675\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "1022 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7475\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "998 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7375\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "987 support vectors out of 1600 points\n",
      "Val Accuracy = 0.735\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "933 support vectors out of 1600 points\n",
      "Val Accuracy = 0.72\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "925 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7325\n",
      "Predicting with mismatch_6 and n_component=800\n",
      "921 support vectors out of 1600 points\n",
      "Val Accuracy = 0.73\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "1015 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7275\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "969 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7275\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "966 support vectors out of 1600 points\n",
      "Val Accuracy = 0.76\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "956 support vectors out of 1600 points\n",
      "Val Accuracy = 0.735\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "930 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7425\n",
      "Predicting with mismatch_6 and n_component=900\n",
      "923 support vectors out of 1600 points\n",
      "Val Accuracy = 0.715\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "1000 support vectors out of 1600 points\n",
      "Val Accuracy = 0.74\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "956 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7625\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "915 support vectors out of 1600 points\n",
      "Val Accuracy = 0.705\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "924 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7075\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "897 support vectors out of 1600 points\n",
      "Val Accuracy = 0.71\n",
      "Predicting with mismatch_6 and n_component=1000\n",
      "914 support vectors out of 1600 points\n",
      "Val Accuracy = 0.7325\n",
      "--------------------------------------------------\n",
      "For the kernel mismatch_6 the best accuracy is 0.7675 with n_components=300 and c=1.5\n",
      "--------------------------------------------------\n",
      "1342 support vectors out of 2000 points\n"
     ]
    }
   ],
   "source": [
    "# With PCA\n",
    "list_c = [0.5, 1, 1.5, 2, 2.5, 3]  \n",
    "sv = 1e-4\n",
    "lambda_log_reg = 1\n",
    "tolerance = 0.001\n",
    "list_kernels = list(gram_matrices_2.keys())\n",
    "list_of_prediction_test_2 = []\n",
    "NComponents = [100*i for i in range(1, 11)]\n",
    "from sklearn.metrics import accuracy_score\n",
    "for kernel in ['mismatch_6']:\n",
    "    ValAcc = np.zeros((len(NComponents), len(list_c)))\n",
    "    for i in range(len(NComponents)):\n",
    "        for j in range(len(list_c)):\n",
    "            \n",
    "            n_component = NComponents[i]\n",
    "            c = list_c[j]\n",
    "\n",
    "            print(f'Predicting with {kernel} and n_component={n_component}')\n",
    "            gram_train_2 = gram_matrices_2[kernel]['train']\n",
    "            \n",
    "            pca = KernelPCA(n_components=n_component)\n",
    "            gram_train_2 = pca.fit_transform(gram_train_2)\n",
    "            gram_train_2 = gram_train_2@gram_train_2.T\n",
    "\n",
    "            test_size = 0.2\n",
    "            list_train, list_val = train_test_split(list(range(2000)), test_size=test_size)\n",
    "            gram_train = gram_train_2[list_train, :][:, list_train]\n",
    "            gram_val = gram_train_2[list_train, :][:, list_val]\n",
    "            y_train_split_2 = Y_train_2[list_train]\n",
    "            y_val_split_2 = Y_train_2[list_val]\n",
    "\n",
    "            svm_test = SVMC(c=c, min_sv=sv)\n",
    "\n",
    "            svm_test.fit(gram_train, y_train_split_2)\n",
    "            y_val_pred = svm_test.predict_class(gram_val).reshape(-1)\n",
    "            val_acc = accuracy_score(y_val_split_2.reshape(-1), y_val_pred)\n",
    "            ValAcc[i, j] = val_acc\n",
    "            print('Val Accuracy =', val_acc)\n",
    "    \n",
    "    best_ncomponent_arg, best_c_arg = np.unravel_index(np.argmax(ValAcc, axis=None), ValAcc.shape) \n",
    "    best_ncomponent = NComponents[best_ncomponent_arg]\n",
    "    best_c = list_c[best_c_arg]\n",
    "    print('--------------------------------------------------')\n",
    "    print('For the kernel {} the best accuracy is {} with n_components={} and c={}'.format(kernel, np.max(ValAcc), best_ncomponent, best_c))\n",
    "    print('--------------------------------------------------')\n",
    "\n",
    "    svm_test = SVMC(c=best_c, min_sv=sv)\n",
    "    pca = KernelPCA(n_components=best_ncomponent)\n",
    "\n",
    "    gram_train_2 = gram_matrices_2[kernel]['train']\n",
    "    gram_train_2_pca = pca.fit_transform(gram_train_2)\n",
    "    gram_train_2 = gram_train_2_pca@gram_train_2_pca.T\n",
    "    svm_test.fit(gram_train_2, Y_train_2)\n",
    "    \n",
    "    gram_test_2 = gram_matrices_2[kernel]['test'].T\n",
    "    gram_test_2_pca = pca.transform(gram_test_2)\n",
    "    gram_test_2 = gram_train_2_pca@gram_test_2_pca.T\n",
    "\n",
    "    y_test_pred_2 = svm_test.predict_class(gram_test_2)\n",
    "    y_test_pred_2[y_test_pred_2 == -1] = 0\n",
    "    list_of_prediction_test_2.append(y_test_pred_2)\n",
    "\n",
    "y_pred_2 = np.array(np.array(list_of_prediction_test_2).mean(axis=0).reshape((-1,))>0.5,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = list(y_pred_0) + list(y_pred_1) + list(y_pred_2)\n",
    "with open(\"outputs/ensembling_kernels_16.csv\", 'w') as f:\n",
    "    f.write('Id,Bound\\n')\n",
    "    for i in range(len(y_pred)):\n",
    "        f.write(str(i)+','+str(y_pred[i])+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}